import numpy as np
import cv2
import sys

from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.applications.vgg16 import preprocess_input
from keras.applications.vgg16 import decode_predictions
from keras.applications.vgg16 import VGG16


class EntityDetector(object):
    """
    Responsible for counting passing entities in a determined area

    Parameters
    ----------
    footage_source : str or int
        The file name or index of video source. In case the source is a video, such file must be in the 'test footage' directory
    look_for : list
        List of classes to be looked for
    confidence_threshold : float (from 0 to 1)
        Detection confidence threshold
    nms_threshold : float (from 0 to 1)
        NMS confidence threshold
    search_area : dictionary 
        Dictionary that defines search area attributes.
        The dictionary must contain a 'position' key and a 'dimension' key, and
            each key contains a tuple of the desired x/y and width/height values
        e.g.: {'position':(715,475),'dimension':(150,35)}
    """

    def __init__(self, footage_source='road footage.mp4', confidence_threshold=0.1 ,look_for=None, search_area={'position': (570, 675), 'dimension': (160, 160)}):

        # LaneCounter changable properties
        self.footage_source = footage_source
        self.look_for = look_for
        self.confidence_threshold = confidence_threshold

        # Input layer shape
        self.width = 224
        self.height = 224

        if (look_for is None):
            self.look_for = ['passenger_car','sports_car','streetcar','recreational_vehicle','police_van','minivan','moving_van','minibus','pickup']
        
        # Search area properties
        try:
            self.search_area_width = int(search_area['dimension'][0])
            self.search_area_height = int(search_area['dimension'][1])
            self.search_area_x = int(search_area['position'][0])
            self.search_area_y = int(search_area['position'][1])
        except:
            print('Invalid search area')
            sys.exit()

    
    def setup(self):
        """
        Responsible for instantiating footage and network
        """
        footage = self.getFootage()

        network = VGG16()

        return footage, network

  
    def detect(self, display=True, console_output=True):
        """
        Counts how many entities pass through search area. 
        To exit counting, press q

        Parameters
        ----------
        display : bool
            In case the footage isn't needed, this parameter can be set to False            

        """
        footage, network = self.setup()

        while(footage.isOpened()):
            ret, frame = footage.read()

            # Converts footage to blob and crops it
            #
            # For more info regarding cv2.dnn.blobFromImage(), go to: https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7
            
            try:
                x_1 = int(self.search_area_x - self.search_area_width/2)
                if(x_1 < 0):
                    x_1 = 0

                x_2 = int(self.search_area_x + self.search_area_width/2)
                if(x_2 >= frame.shape[1]):
                    x_2 = frame.shape[1] - 1

                y_1 = int(self.search_area_y - self.search_area_height/2)
                if(y_1 < 0):
                    y_1 = 0

                y_2 = int(self.search_area_y + self.search_area_height/2)
                if(y_2 >= frame.shape[0]):
                    y_2 = frame.shape[0] - 1

                frame = frame[y_1:y_2,x_1:x_2]
            except:
                print('Invalid search area')

            # Converts footage frame to CNN input
            try:                
                input_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            except:
                sys.exit()
            input_frame = cv2.resize(input_frame, (self.width, self.height))
            input_frame = np.expand_dims(input_frame, axis=0)            

            # Preprocesses input
            processed_input = preprocess_input(input_frame)

            # Predicts output
            prediction = network.predict(processed_input)

            # Assign the prediction to a class
            decoded_prediction = decode_predictions(prediction)

            # Gets the most confident result
            most_confident_result = decoded_prediction[0][0]

            entity , confidence =  most_confident_result[1] ,  most_confident_result[2]
            
            if(entity in self.look_for and confidence >= self.confidence_threshold and console_output):                    
                print("{} % -{}".format(int(confidence*100),entity))
                # sys.stdout.flush()
            
            # Displays footage and detection (can be disable)
            if(display):
                if(entity in self.look_for and confidence >= self.confidence_threshold):
                    cv2.putText(frame, "{} %-{}".format(int(confidence*100),entity),
                        (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 0, 200), 2)                
                else:
                    cv2.putText(frame, "No results",
                        (5, 20), cv2.FONT_HERSHEY_SIMPLEX,0.5, (200, 0, 200), 2)            
                cv2.imshow('CVE Footage', frame)
                            
            # Press q to exit
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break            

        footage.release()
        cv2.destroyAllWindows()

        # Returns counting
        return

    def getFootage(self):
        """
        Instantiates OpenCV footage based on source
        """

        # OpenCV's "VideoCapture()" method's parameter is either an index (which is related to a connected source) or a filename
        #
        # For more info regarding cv2.VideoCapture(), go to: https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html#a57c0e81e83e60f36c83027dc2a188e80
        footage = cv2.VideoCapture(self.footage_source)

        # Checks wether or not the given source is a valid one
        if footage is None or not footage.isOpened():
            print('Invalid source')
            sys.exit()

        return footage
